{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Generation Demo\n",
    "\n",
    "This notebook demonstrates face generation process of the\n",
    "method described in the paper \"PixelCNN Models with Auxiliary Variables for Natural Image Generation\": \n",
    "http://proceedings.mlr.press/v70/kolesnikov17a.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load tensorflow utils and models\n",
    "import utils\n",
    "\n",
    "# Fix random seed for reproducable results\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "# Load visualization libraries\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy.ndimage as nd\n",
    "import cPickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computational mode. 'gpu' mode is recommended, 'cpu' mode can be quite slow.\n",
    "mode = 'cpu'  # or 'cpu' is possible\n",
    "\n",
    "# List of GPUs to use\n",
    "gpu_list = [0]\n",
    "num_gpus = len(gpu_list)\n",
    "\n",
    "# Number of pyramid layers\n",
    "num_pyramid_layers = 5\n",
    "\n",
    "# Number of pyramid layers to generate (up to 5)\n",
    "num_pyramid_layers_to_generate = 3\n",
    "\n",
    "# Batch size\n",
    "batch_size_per_gpu = 4\n",
    "batch_size = batch_size_per_gpu * num_gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Pyramid PixelCNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('Resnet') as scope:\n",
    "    \n",
    "    # Create placeholder for images, which should be generated\n",
    "    images = tf.placeholder(shape=[batch_size, None, None, 3], dtype=tf.float32)\n",
    "    \n",
    "    # Build multi-scale image pyramid\n",
    "    images_pyramid = utils.get_pyramid(images, num_pyramid_layers - 1)\n",
    "    \n",
    "    pyramid_embeddings = []\n",
    "    pyramid_predicted_images = []\n",
    "    \n",
    "    # Each iterations creates one Pyramid layer\n",
    "    for layer_i in range(num_pyramid_layers):\n",
    "        with tf.variable_scope('scale%d' % layer_i) as scope:\n",
    "    \n",
    "            images_current = images_pyramid[layer_i]\n",
    "            images_prev = images_pyramid[layer_i + 1]\n",
    "\n",
    "            # Technical step needed to properly create variables ####\n",
    "            tf.GLOBAL['init'] = True\n",
    "            _ = utils.PyramidPixelCNN(images_current, images_prev)\n",
    "            tf.GLOBAL['init'] = False\n",
    "            scope.reuse_variables()\n",
    "            ##########################################################\n",
    "            \n",
    "            images_current_gpu_parts = tf.split(images_current, num_gpus, 0)\n",
    "            images_prev_gpu_parts = (tf.split(images_prev, num_gpus, 0)\n",
    "                                     if images_prev is not None\n",
    "                                     else [None] * num_gpus)\n",
    "\n",
    "            predicted_images = []\n",
    "            embeddings = []\n",
    "\n",
    "            for i, gpu_i in enumerate(gpu_list): \n",
    "                with tf.device('/gpu:%i' % gpu_i if mode == 'gpu' else '/cpu:0'):\n",
    "                    \n",
    "                    # Build tensorflow model for one super-resolution step\n",
    "                    p, e = utils.PyramidPixelCNN(images_current_gpu_parts[i],\n",
    "                                                 images_prev_gpu_parts[i])\n",
    "                    predicted_images.append(p)\n",
    "                    embeddings.append(e)\n",
    "\n",
    "            pyramid_predicted_images.append(predicted_images)\n",
    "            pyramid_embeddings.append(embeddings)\n",
    "     \n",
    "    \n",
    "# Create Tensorflow expression to sample from the predicted pixel distributions \n",
    "variance = tf.placeholder(shape=[], dtype=tf.float32)\n",
    "samples = [utils.sample_from_discretized_mix_logistic(tf.concat([pp for pp in p], 0), variance)\n",
    "           for p in pyramid_predicted_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This function implements sequential pixel-wise sampling for a given pyramid layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_from_model_at_layer(layer_i, image_prev_layer, sess, change_variance=0.0):\n",
    "    \n",
    "    # Infer resolution for the current layer\n",
    "    resolution = 2 ** (int(np.log2(128)) - layer_i)\n",
    "    \n",
    "    if image_prev_layer is not None:\n",
    "        x_gen = nd.zoom(image_prev_layer, (1, 2, 2, 1), order=0)\n",
    "    else:\n",
    "        x_gen = np.zeros((batch_size, resolution, resolution, 3))\n",
    "        \n",
    "    # Compute embedding of the image from the previous pyramid layer\n",
    "    if pyramid_embeddings[layer_i][0] is not None:\n",
    "        embedding_current = sess.run(pyramid_embeddings[layer_i],\n",
    "                                     {images_pyramid[layer_i + 1]: image_prev_layer})\n",
    "    else:\n",
    "        embedding_current = None\n",
    "    \n",
    "    # Create figure to visualize sampling preocess\n",
    "    f = plt.figure(figsize=(24, 8))\n",
    "    \n",
    "    # Run cycle over every pixel in the image\n",
    "    for yi in range(resolution):\n",
    "        for xi in range(resolution):\n",
    "    \n",
    "            FOV = 16\n",
    "            if x_gen.shape[1] <= FOV:\n",
    "                x_feed = x_gen\n",
    "                y_sample = yi\n",
    "                x_sample = xi\n",
    "                embedding_feed = embedding_current\n",
    "            else:\n",
    "                cut_y, cut_x = 0, 0\n",
    "                y_sample = yi\n",
    "                x_sample = xi\n",
    "                if yi >= FOV:\n",
    "                    cut_y = yi - FOV + 1\n",
    "                    y_sample = -1\n",
    "                if xi >= FOV / 2:\n",
    "                    cut_x = xi - FOV / 2\n",
    "                    x_sample = FOV / 2\n",
    "                x_feed = x_gen[:, cut_y:cut_y + FOV, cut_x:cut_x + FOV, :]\n",
    "                embedding_feed = [e[:, cut_y:cut_y + FOV, cut_x:cut_x + FOV, :] for e in embedding_current]\n",
    "                    \n",
    "            # Sample new pixel\n",
    "            feed = {images_pyramid[layer_i]: x_feed, variance: change_variance}\n",
    "            if embedding_current is not None:\n",
    "                [feed.update({pyramid_embeddings[layer_i][i]: r}) for i, r in enumerate(embedding_feed)]\n",
    "            new_pixel = sess.run(samples[layer_i], feed)\n",
    "            \n",
    "            # Update current image\n",
    "            x_gen[:, yi, xi, :] = new_pixel[:, y_sample, x_sample, :]\n",
    "            \n",
    "            # Add green pixel to simplify tracking of sampling process\n",
    "            if (xi + 1) < resolution:\n",
    "                 x_gen[:, yi, xi + 1, :] = np.array([0, 1.0, 0])[None]\n",
    "            elif (yi + 1) < resolution:\n",
    "                x_gen[:, yi + 1, 0, :] = np.array([0, 1.0, 0])[None]\n",
    "             \n",
    "            # Visualize current image ###################################\n",
    "            \n",
    "            # Set frequency of updates\n",
    "            freq_update = {4: 3, 3: 20, 2: 70, 1: 70}\n",
    "            \n",
    "            if (yi * resolution + xi) % freq_update[layer_i] == 0:\n",
    "                # Plot images\n",
    "                for i in range(batch_size):\n",
    "                    ax = f.add_subplot(1, batch_size, i + 1)\n",
    "                    ax.imshow(utils.unprepro(x_gen[i]).astype('uint8'), interpolation='nearest')\n",
    "                    ax.axis('off')\n",
    "                display.display(plt.gcf())\n",
    "                display.clear_output(wait=True)\n",
    "                plt.clf()\n",
    "                \n",
    "            ###############################################################\n",
    "      \n",
    "    # Plot final samples\n",
    "    for i in range(batch_size):\n",
    "        ax = f.add_subplot(1, batch_size, i + 1)\n",
    "        ax.imshow(utils.unprepro(x_gen[i]).astype('uint8'))\n",
    "        ax.axis('off')\n",
    "\n",
    "    return x_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve pretrained model\n",
    "if not os.path.exists('model.pickle'):\n",
    "    import urllib\n",
    "    model_file = urllib.URLopener()\n",
    "    print('Downloading the pretrained model...')\n",
    "    model_file.retrieve(\"https://pub.ist.ac.at/~akolesnikov/files/model.pickle\", \"model.pickle\")\n",
    "    print('Finished')\n",
    "    \n",
    "inits = utils.get_weight_initializer(dict(cPickle.load(open('model.pickle'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variance_change is a crucial parameter, which controls variance of the sampled pixels\n",
    "Negative values of this variable artifically reduce variance of the predicted pixel distribution and lead to better perceptual quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variance_change = -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tensorflow session and run the computaitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABWAAAAFGCAYAAADkTTblAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3b22acab10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    # Load pretrained weights\n",
    "    sess.run(inits)\n",
    "\n",
    "    # Produce samples\n",
    "    image_list = [None]\n",
    "    for layer_i in range(num_pyramid_layers_to_generate):\n",
    "        sample = sample_from_model_at_layer(num_pyramid_layers - layer_i - 1,\n",
    "                                            image_list[-1], sess, variance_change)\n",
    "        image_list.append(sample)         \n",
    "    image_list = image_list[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try higher variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variance_change = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(inits)\n",
    "\n",
    "    image_list = [None]\n",
    "\n",
    "    for layer_i in range(num_pyramid_layers_to_generate):\n",
    "        sample = sample_from_model_at_layer(num_pyramid_layers - layer_i - 1,\n",
    "                                            image_list[-1], sess, variance_change)\n",
    "        image_list.append(sample)\n",
    "            \n",
    "    image_list = image_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
